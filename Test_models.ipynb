{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onWf-eEGM4zF",
        "outputId": "d1778292-7d4d-4262-adee-33fe39c4ec73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77Ys3hJNVOu3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import json\n",
        "import librosa\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential, save_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2dad0V-WKPs"
      },
      "outputs": [],
      "source": [
        "\n",
        "filepath = '/content/drive/MyDrive/data.json'\n",
        "\n",
        "with open(filepath, \"r\") as fp:\n",
        "    data = json.load(fp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gMMi5QPWr6t"
      },
      "outputs": [],
      "source": [
        "def plot_mfcc(mfcc, fs, fig_size=(12,6)):\n",
        "    \"\"\"Plots the mel-scaled spectrogram from mfccs. This is performing the same task as\n",
        "    'plot_mel_spectrogram_audio' with just a different input.\n",
        "\n",
        "    Parameters:\n",
        "        mfcc (numpy.ndarray): mfccs of an audio signal\n",
        "        fs (int): sampling frequency (Hz) of audio signal\n",
        "        fig_size (tuple): Dimensions of figure\n",
        "    \"\"\"\n",
        "    # Plot Spectrogram\n",
        "    plt.figure(figsize=fig_size)\n",
        "\n",
        "    # Display the spectrogram on a mel scale\n",
        "    # sample rate and hop length parameters are used to render the time axis\n",
        "    # abs on signal for better visualization\n",
        "    librosa.display.specshow(data=mfcc, sr=fs, x_axis='time', y_axis='linear', cmap='viridis')\n",
        "\n",
        "    # Put a descriptive title on the plot\n",
        "    plt.title('MFCCs')\n",
        "\n",
        "    # draw a color bar\n",
        "    plt.colorbar(format='%+02.0f dB')\n",
        "\n",
        "    # Make the figure layout compact\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "J-jzGmvuW4t2",
        "outputId": "e9f30e2c-b475-4a39-cbac-2ec41a4f820e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "idx = 1000\n",
        "fs = 22500\n",
        "plot_mfcc(np.array(data[\"mfcc\"])[idx].T, fs)\n",
        "plt.title(f\"{np.array(data['genre_name'])[idx].title()}\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnBl89TaYUgn"
      },
      "outputs": [],
      "source": [
        "X = np.array(data[\"mfcc\"])\n",
        "y = np.array(data[\"genre_num\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYe1IO_tW_3v",
        "outputId": "ad3d00f5-ada9-4c70-ebe5-ad31c915661e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X training data shape: (4894, 132, 13), y training data shape: (4894,)\n",
            "X validation data shape: (2098, 132, 13), y validation data shape: (2098,)\n"
          ]
        }
      ],
      "source": [
        "# Train-validation-test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42, stratify=y_train)\n",
        "\n",
        "# shape = (# samples, time-bins (x), num MFCCs (y))\n",
        "print(f\"X training data shape: {X_train.shape}, y training data shape: {y_train.shape}\")\n",
        "print(f\"X validation data shape: {X_val.shape}, y validation data shape: {y_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRxHn1XgYTy3"
      },
      "outputs": [],
      "source": [
        "def plot_history(hist):\n",
        "    \"\"\"Plots the accuracy and loss for a model over the course of all epochs\n",
        "\n",
        "    Parameters:\n",
        "        hist (keras history object): The recorded history of model.fit() to be plotted\n",
        "    \"\"\"\n",
        "    fig, axs = plt.subplots(2, 1, figsize=(8,7))\n",
        "    fig.tight_layout(pad=2)\n",
        "\n",
        "    # Accuracy subplot\n",
        "    axs[0].plot(hist.history[\"acc\"], c='navy', label=\"Training Accuracy\")\n",
        "    axs[0].plot(hist.history[\"val_acc\"], c='orange', label=\"Validation Accuracy\")\n",
        "    axs[0].set_ylabel(\"Accuracy\")\n",
        "    axs[0].legend(loc=\"lower right\")\n",
        "    axs[0].set_title(\"Accuracy\")\n",
        "\n",
        "    # Error subplot\n",
        "    axs[1].plot(hist.history[\"loss\"], c='navy', label=\"Training Loss\")\n",
        "    axs[1].plot(hist.history[\"val_loss\"], c='orange', label=\"Validation Loss\")\n",
        "    axs[1].set_ylabel(\"Loss\")\n",
        "    axs[1].set_xlabel(\"Epochs\")\n",
        "    axs[1].legend(loc=\"upper right\")\n",
        "    axs[1].set_title(\"Loss\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSwMmAsaYZ3i",
        "outputId": "9a7442be-c6f3-4986-ff26-2662b492fa3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4894, 132, 13, 1)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add additional dimension for CNN\n",
        "X_train_cnn = X_train[..., np.newaxis]\n",
        "X_val_cnn = X_val[..., np.newaxis]\n",
        "X_test_cnn = X_test[..., np.newaxis]\n",
        "\n",
        "input_shape = X_train_cnn.shape[1:4]\n",
        "X_train_cnn.shape # shape = (# samples, time-bins (x), num MFCCs (y), \"channel\" (like an image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o-dzIg-Nwj5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qgw1ODvSFCMR"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_cnn00 = Sequential()\n",
        "\n",
        "\n",
        "model_cnn00.add(Conv2D(8, 3, activation='sigmoid', input_shape=input_shape))\n",
        "model_cnn00.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn00.add(Flatten())\n",
        "\n",
        "model_cnn00.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dANfLUgbFCnh"
      },
      "outputs": [],
      "source": [
        "model_cnn00.compile(optimizer=Adam(learning_rate=0.1),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6mFPj6MFCya",
        "outputId": "f5b66b5d-2eab-4b44-d7b3-9d41e81750f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "\u001b[1m1632/1632\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.1783 - loss: 210.0198 - val_accuracy: 0.2817 - val_loss: 131.3966\n",
            "Epoch 2/4\n",
            "\u001b[1m1632/1632\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.2959 - loss: 161.9160 - val_accuracy: 0.3074 - val_loss: 232.4100\n",
            "Epoch 3/4\n",
            "\u001b[1m1632/1632\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3162 - loss: 172.8951 - val_accuracy: 0.2750 - val_loss: 214.2821\n",
            "Epoch 4/4\n",
            "\u001b[1m1632/1632\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3320 - loss: 187.4890 - val_accuracy: 0.2822 - val_loss: 202.6190\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "hist_cnn00 = model_cnn00.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    validation_data=(X_val_cnn, y_val),\n",
        "    batch_size=3,\n",
        "    epochs=4,\n",
        "    verbose=1\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLLtjzoXN3gz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "oCO3qgyOQXc0",
        "outputId": "deccab08-125c-42d4-a100-b795636c4437"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> \n",
              "\n",
              " max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                   (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3120</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">31,210</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m8\u001b[0m)                        \u001b[38;5;34m80\u001b[0m \n",
              "\n",
              " max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)        (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)                   (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3120\u001b[0m)                               \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_5 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                            \u001b[38;5;34m31,210\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,872</span> (366.69 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,872\u001b[0m (366.69 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,290</span> (122.23 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,290\u001b[0m (122.23 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">62,582</span> (244.46 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m62,582\u001b[0m (244.46 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_cnn00.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQZCE0_MIRK5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model_cnn01 = Sequential()\n",
        "\n",
        "model_cnn01.add(Conv2D(8, 3, activation='sigmoid', input_shape=input_shape, padding='same'))\n",
        "model_cnn01.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "\n",
        "\n",
        "model_cnn01.add(Conv2D(32, 3, activation='sigmoid', padding='same')) #\n",
        "model_cnn01.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn01.add(Flatten())\n",
        "\n",
        "model_cnn01.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0jPenU0KHyS"
      },
      "outputs": [],
      "source": [
        "model_cnn01.compile(optimizer=Adam(learning_rate=0.01),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXKpWmUjJUCY",
        "outputId": "37b83a21-2440-4029-e3c8-14cc8e2e19d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m408/408\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.1173 - loss: 3.1900 - val_accuracy: 0.1654 - val_loss: 2.2344\n",
            "Epoch 2/8\n",
            "\u001b[1m408/408\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2270 - loss: 2.1305 - val_accuracy: 0.3308 - val_loss: 1.8859\n",
            "Epoch 3/8\n",
            "\u001b[1m408/408\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.3307 - loss: 1.8860 - val_accuracy: 0.3356 - val_loss: 1.8451\n",
            "Epoch 4/8\n",
            "\u001b[1m408/408\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.3587 - loss: 1.8008 - val_accuracy: 0.3518 - val_loss: 1.7838\n",
            "Epoch 5/8\n",
            "\u001b[1m408/408\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.3947 - loss: 1.7019 - val_accuracy: 0.3356 - val_loss: 1.7889\n",
            "Epoch 6/8\n",
            "\u001b[1m408/408\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4178 - loss: 1.6595 - val_accuracy: 0.3608 - val_loss: 1.7825\n",
            "Epoch 7/8\n",
            "\u001b[1m408/408\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4085 - loss: 1.6277 - val_accuracy: 0.3575 - val_loss: 1.8526\n",
            "Epoch 8/8\n",
            "\u001b[1m408/408\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4258 - loss: 1.5916 - val_accuracy: 0.3499 - val_loss: 1.8465\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "hist_cnn01 = model_cnn01.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    validation_data=(X_val_cnn, y_val),\n",
        "    batch_size=12,\n",
        "    epochs=8,\n",
        "    verbose=1\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "AyMm96oaQa1W",
        "outputId": "ead74797-ca20-4426-92e0-fccfdaa08dc1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> \n",
              "\n",
              " max_pooling2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,336</span> \n",
              "\n",
              " max_pooling2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4224</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">42,250</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m8\u001b[0m)                        \u001b[38;5;34m80\u001b[0m \n",
              "\n",
              " max_pooling2d_24 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      \u001b[38;5;34m2,336\u001b[0m \n",
              "\n",
              " max_pooling2d_25 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4224\u001b[0m)                               \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_11 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                            \u001b[38;5;34m42,250\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,000</span> (523.44 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,000\u001b[0m (523.44 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">44,666</span> (174.48 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m44,666\u001b[0m (174.48 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">89,334</span> (348.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m89,334\u001b[0m (348.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_cnn01.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TkjTWwpPyLa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DU3XV9TZLMgz"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_cnn02 = Sequential()\n",
        "\n",
        "\n",
        "model_cnn02.add(Conv2D(8, 3, activation='relu', input_shape=input_shape, padding='same'))\n",
        "model_cnn02.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "\n",
        "model_cnn02.add(Conv2D(16, 3, activation='relu', padding='same'))\n",
        "model_cnn02.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn02.add(Conv2D(32, 3, activation='relu', padding='same'))\n",
        "model_cnn02.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn02.add(Flatten())\n",
        "\n",
        "model_cnn02.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ql879okJEVE"
      },
      "outputs": [],
      "source": [
        "model_cnn02.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nuUzSC3JEdo",
        "outputId": "81ae6741-0e05-467b-dbbf-93f5fa69b633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.2721 - loss: 4.0236 - val_accuracy: 0.3875 - val_loss: 1.6677\n",
            "Epoch 2/8\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4714 - loss: 1.4129 - val_accuracy: 0.4814 - val_loss: 1.4584\n",
            "Epoch 3/8\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5188 - loss: 1.2850 - val_accuracy: 0.5253 - val_loss: 1.3060\n",
            "Epoch 4/8\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5829 - loss: 1.1372 - val_accuracy: 0.5520 - val_loss: 1.2516\n",
            "Epoch 5/8\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6183 - loss: 1.0477 - val_accuracy: 0.5829 - val_loss: 1.1607\n",
            "Epoch 6/8\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6636 - loss: 0.9556 - val_accuracy: 0.5758 - val_loss: 1.2252\n",
            "Epoch 7/8\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6905 - loss: 0.8624 - val_accuracy: 0.5887 - val_loss: 1.1874\n",
            "Epoch 8/8\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.7926 - val_accuracy: 0.6111 - val_loss: 1.2011\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "hist_cnn02 = model_cnn02.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    validation_data=(X_val_cnn, y_val),\n",
        "    batch_size=16,\n",
        "    epochs=8,\n",
        "    verbose=1\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "5xb16yo6QdpH",
        "outputId": "f9cbeebf-ad39-4b03-a1d5-bc8bb2da4276"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> \n",
              "\n",
              " max_pooling2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                           <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,168</span> \n",
              "\n",
              " max_pooling2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> \n",
              "\n",
              " max_pooling2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1088</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">10,890</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m8\u001b[0m)                        \u001b[38;5;34m80\u001b[0m \n",
              "\n",
              " max_pooling2d_35 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)                           \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_36 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)                      \u001b[38;5;34m1,168\u001b[0m \n",
              "\n",
              " max_pooling2d_36 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m16\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_37 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      \u001b[38;5;34m4,640\u001b[0m \n",
              "\n",
              " max_pooling2d_37 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m32\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten_15 (\u001b[38;5;33mFlatten\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1088\u001b[0m)                               \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_15 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                            \u001b[38;5;34m10,890\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,336</span> (196.63 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,336\u001b[0m (196.63 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,778</span> (65.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,778\u001b[0m (65.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,558</span> (131.09 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m33,558\u001b[0m (131.09 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_cnn02.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn1KCUeaQV8L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YpDAEXKLyEP"
      },
      "outputs": [],
      "source": [
        "model_cnn03 = Sequential()\n",
        "\n",
        "model_cnn03.add(Conv2D(32, 3, activation='relu', input_shape=input_shape, padding='same'))\n",
        "model_cnn03.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn03.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model_cnn03.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn03.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model_cnn03.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn03.add(Flatten())\n",
        "\n",
        "model_cnn03.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsGkm41lNtMJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_cnn03.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvaoFu0hLqBW",
        "outputId": "53a07d0a-e910-4e40-8b09-7fc5ec0700d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - accuracy: 0.3180 - loss: 3.7539 - val_accuracy: 0.4404 - val_loss: 1.5724\n",
            "Epoch 2/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.4879 - loss: 1.3953 - val_accuracy: 0.5148 - val_loss: 1.3414\n",
            "Epoch 3/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5668 - loss: 1.2148 - val_accuracy: 0.5772 - val_loss: 1.2307\n",
            "Epoch 4/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6240 - loss: 1.0605 - val_accuracy: 0.6034 - val_loss: 1.1487\n",
            "Epoch 5/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.6315 - loss: 1.0076 - val_accuracy: 0.6230 - val_loss: 1.0784\n",
            "Epoch 6/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6834 - loss: 0.8825 - val_accuracy: 0.6053 - val_loss: 1.1121\n",
            "Epoch 7/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7062 - loss: 0.7983 - val_accuracy: 0.6187 - val_loss: 1.1703\n",
            "Epoch 8/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7399 - loss: 0.7338 - val_accuracy: 0.6249 - val_loss: 1.1443\n",
            "Epoch 9/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7658 - loss: 0.6575 - val_accuracy: 0.5724 - val_loss: 1.4245\n",
            "Epoch 10/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7846 - loss: 0.6236 - val_accuracy: 0.6168 - val_loss: 1.3205\n",
            "Epoch 11/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.4943 - val_accuracy: 0.6397 - val_loss: 1.2060\n",
            "Epoch 12/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8298 - loss: 0.4668 - val_accuracy: 0.6339 - val_loss: 1.2260\n",
            "Epoch 13/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8491 - loss: 0.4168 - val_accuracy: 0.6206 - val_loss: 1.4178\n",
            "Epoch 14/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8733 - loss: 0.3535 - val_accuracy: 0.6501 - val_loss: 1.3580\n",
            "Epoch 15/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 0.3061 - val_accuracy: 0.6373 - val_loss: 1.3877\n",
            "Epoch 16/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.3273 - val_accuracy: 0.6663 - val_loss: 1.5199\n",
            "Epoch 17/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9190 - loss: 0.2411 - val_accuracy: 0.6306 - val_loss: 1.7173\n",
            "Epoch 18/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9077 - loss: 0.2727 - val_accuracy: 0.6411 - val_loss: 1.7966\n",
            "Epoch 19/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9208 - loss: 0.2331 - val_accuracy: 0.6158 - val_loss: 2.0955\n",
            "Epoch 20/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.2830 - val_accuracy: 0.6416 - val_loss: 1.7582\n",
            "Epoch 21/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.1361 - val_accuracy: 0.6306 - val_loss: 1.9241\n",
            "Epoch 22/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9283 - loss: 0.2166 - val_accuracy: 0.6439 - val_loss: 2.1797\n",
            "Epoch 23/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.2827 - val_accuracy: 0.6478 - val_loss: 2.0011\n",
            "Epoch 24/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9372 - loss: 0.1841 - val_accuracy: 0.6373 - val_loss: 2.1974\n",
            "Epoch 25/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.2006 - val_accuracy: 0.6463 - val_loss: 1.9712\n",
            "Epoch 26/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9371 - loss: 0.1930 - val_accuracy: 0.5996 - val_loss: 2.4655\n",
            "Epoch 27/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9405 - loss: 0.1889 - val_accuracy: 0.6454 - val_loss: 2.5335\n",
            "Epoch 28/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9347 - loss: 0.2113 - val_accuracy: 0.6058 - val_loss: 2.8452\n",
            "Epoch 29/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.2081 - val_accuracy: 0.6487 - val_loss: 2.3249\n",
            "Epoch 30/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9541 - loss: 0.1641 - val_accuracy: 0.6535 - val_loss: 2.4898\n",
            "Epoch 31/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9678 - loss: 0.0928 - val_accuracy: 0.6435 - val_loss: 2.5775\n",
            "Epoch 32/32\n",
            "\u001b[1m306/306\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9397 - loss: 0.1948 - val_accuracy: 0.6211 - val_loss: 3.0057\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "hist_cnn03 = model_cnn03.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    validation_data=(X_val_cnn, y_val),\n",
        "    batch_size=16,\n",
        "    epochs=32,\n",
        "    verbose=1\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "aPmExsxsZapq",
        "outputId": "005a69e8-36fc-45c2-f9a5-4ee2e3020f58"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " conv2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> \n",
              "\n",
              " max_pooling2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> \n",
              "\n",
              " max_pooling2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " conv2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> \n",
              "\n",
              " max_pooling2d_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " flatten_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2176</span>)                               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                            <span style=\"color: #00af00; text-decoration-color: #00af00\">21,770</span> \n",
              "\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " conv2d_38 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m132\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)                      \u001b[38;5;34m320\u001b[0m \n",
              "\n",
              " max_pooling2d_38 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m66\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m18,496\u001b[0m \n",
              "\n",
              " max_pooling2d_39 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " conv2d_40 (\u001b[38;5;33mConv2D\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)                     \u001b[38;5;34m36,928\u001b[0m \n",
              "\n",
              " max_pooling2d_40 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)                          \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " flatten_16 (\u001b[38;5;33mFlatten\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2176\u001b[0m)                               \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense_16 (\u001b[38;5;33mDense\u001b[0m)                      (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                            \u001b[38;5;34m21,770\u001b[0m \n",
              "\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">232,544</span> (908.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m232,544\u001b[0m (908.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,514</span> (302.79 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m77,514\u001b[0m (302.79 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">155,030</span> (605.59 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m155,030\u001b[0m (605.59 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_cnn03.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_D2GhVTLke-6"
      },
      "outputs": [],
      "source": [
        "model_cnn04 = Sequential()\n",
        "\n",
        "model_cnn04.add(Conv2D(32, 3, activation='relu', input_shape=input_shape, padding='same'))\n",
        "model_cnn04.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn04.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model_cnn04.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn04.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model_cnn04.add(MaxPooling2D(3, strides=(2,2), padding='same'))\n",
        "\n",
        "model_cnn04.add(Flatten())\n",
        "model_cnn04.add(Dense(64, activation='relu'))\n",
        "\n",
        "model_cnn04.add(Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfxtIHWCXBNt"
      },
      "outputs": [],
      "source": [
        "model_cnn04.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVi1YCOfXMVZ",
        "outputId": "27c95a8b-a4b1-4f7b-9da7-5a25c449c620"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - acc: 0.1543 - loss: 8.8743 - val_acc: 0.3008 - val_loss: 2.3263\n",
            "Epoch 2/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - acc: 0.2995 - loss: 2.2427 - val_acc: 0.3594 - val_loss: 1.9567\n",
            "Epoch 3/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.3717 - loss: 1.8529 - val_acc: 0.3923 - val_loss: 1.7417\n",
            "Epoch 4/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.4286 - loss: 1.6441 - val_acc: 0.4342 - val_loss: 1.6005\n",
            "Epoch 5/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.4709 - loss: 1.4599 - val_acc: 0.4519 - val_loss: 1.5878\n",
            "Epoch 6/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.5119 - loss: 1.3643 - val_acc: 0.4871 - val_loss: 1.4282\n",
            "Epoch 7/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.5468 - loss: 1.2892 - val_acc: 0.5010 - val_loss: 1.4015\n",
            "Epoch 8/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.5623 - loss: 1.2263 - val_acc: 0.5153 - val_loss: 1.3625\n",
            "Epoch 9/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.5917 - loss: 1.1366 - val_acc: 0.5505 - val_loss: 1.3160\n",
            "Epoch 10/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.6192 - loss: 1.0669 - val_acc: 0.5419 - val_loss: 1.2802\n",
            "Epoch 11/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.6271 - loss: 1.0422 - val_acc: 0.5453 - val_loss: 1.2634\n",
            "Epoch 12/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.6434 - loss: 0.9903 - val_acc: 0.5739 - val_loss: 1.2160\n",
            "Epoch 13/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.6650 - loss: 0.9404 - val_acc: 0.5777 - val_loss: 1.2119\n",
            "Epoch 14/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.6656 - loss: 0.9408 - val_acc: 0.5777 - val_loss: 1.2321\n",
            "Epoch 15/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.6872 - loss: 0.8894 - val_acc: 0.5844 - val_loss: 1.1914\n",
            "Epoch 16/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.6882 - loss: 0.8886 - val_acc: 0.5844 - val_loss: 1.2381\n",
            "Epoch 17/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.7013 - loss: 0.8567 - val_acc: 0.6201 - val_loss: 1.1084\n",
            "Epoch 18/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.7455 - loss: 0.7488 - val_acc: 0.6120 - val_loss: 1.1384\n",
            "Epoch 19/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.7476 - loss: 0.7567 - val_acc: 0.6168 - val_loss: 1.1078\n",
            "Epoch 20/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.7509 - loss: 0.7276 - val_acc: 0.6206 - val_loss: 1.1286\n",
            "Epoch 21/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.7639 - loss: 0.7017 - val_acc: 0.6330 - val_loss: 1.0935\n",
            "Epoch 22/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.7759 - loss: 0.6457 - val_acc: 0.6459 - val_loss: 1.0499\n",
            "Epoch 23/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.7888 - loss: 0.6243 - val_acc: 0.6516 - val_loss: 1.0319\n",
            "Epoch 24/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.8000 - loss: 0.5986 - val_acc: 0.6578 - val_loss: 1.0382\n",
            "Epoch 25/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.8111 - loss: 0.5916 - val_acc: 0.6373 - val_loss: 1.0827\n",
            "Epoch 26/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.8293 - loss: 0.5444 - val_acc: 0.6511 - val_loss: 1.0558\n",
            "Epoch 27/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.8145 - loss: 0.5449 - val_acc: 0.6511 - val_loss: 1.0406\n",
            "Epoch 28/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.8346 - loss: 0.5089 - val_acc: 0.6716 - val_loss: 1.0105\n",
            "Epoch 29/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.8481 - loss: 0.4882 - val_acc: 0.6640 - val_loss: 1.0055\n",
            "Epoch 30/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.8480 - loss: 0.4793 - val_acc: 0.6778 - val_loss: 0.9676\n",
            "Epoch 31/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.8612 - loss: 0.4462 - val_acc: 0.6826 - val_loss: 0.9903\n",
            "Epoch 32/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.8774 - loss: 0.4053 - val_acc: 0.6864 - val_loss: 0.9943\n",
            "Epoch 33/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.8772 - loss: 0.3964 - val_acc: 0.6768 - val_loss: 1.0010\n",
            "Epoch 34/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.8825 - loss: 0.3755 - val_acc: 0.6849 - val_loss: 0.9826\n",
            "Epoch 35/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9005 - loss: 0.3486 - val_acc: 0.6730 - val_loss: 0.9836\n",
            "Epoch 36/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.8955 - loss: 0.3559 - val_acc: 0.6868 - val_loss: 1.0166\n",
            "Epoch 37/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9057 - loss: 0.3302 - val_acc: 0.6773 - val_loss: 0.9898\n",
            "Epoch 38/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9124 - loss: 0.3182 - val_acc: 0.7011 - val_loss: 0.9351\n",
            "Epoch 39/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9278 - loss: 0.2850 - val_acc: 0.6949 - val_loss: 0.9649\n",
            "Epoch 40/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9211 - loss: 0.2803 - val_acc: 0.6921 - val_loss: 1.0291\n",
            "Epoch 41/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9293 - loss: 0.2670 - val_acc: 0.6949 - val_loss: 0.9897\n",
            "Epoch 42/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9366 - loss: 0.2490 - val_acc: 0.7050 - val_loss: 0.9731\n",
            "Epoch 43/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9388 - loss: 0.2387 - val_acc: 0.6978 - val_loss: 1.0298\n",
            "Epoch 44/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9383 - loss: 0.2482 - val_acc: 0.6978 - val_loss: 0.9867\n",
            "Epoch 45/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9467 - loss: 0.2176 - val_acc: 0.6773 - val_loss: 1.0994\n",
            "Epoch 46/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.9214 - loss: 0.2608 - val_acc: 0.7121 - val_loss: 0.9933\n",
            "Epoch 47/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9590 - loss: 0.1896 - val_acc: 0.7064 - val_loss: 1.0022\n",
            "Epoch 48/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9633 - loss: 0.1780 - val_acc: 0.7050 - val_loss: 0.9779\n",
            "Epoch 49/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9611 - loss: 0.1728 - val_acc: 0.7035 - val_loss: 1.0010\n",
            "Epoch 50/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9511 - loss: 0.1920 - val_acc: 0.6983 - val_loss: 1.0974\n",
            "Epoch 51/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9533 - loss: 0.1843 - val_acc: 0.7178 - val_loss: 1.0091\n",
            "Epoch 52/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9655 - loss: 0.1535 - val_acc: 0.7088 - val_loss: 1.0045\n",
            "Epoch 53/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9745 - loss: 0.1369 - val_acc: 0.7131 - val_loss: 1.0072\n",
            "Epoch 54/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9679 - loss: 0.1439 - val_acc: 0.7135 - val_loss: 1.0375\n",
            "Epoch 55/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9745 - loss: 0.1230 - val_acc: 0.7169 - val_loss: 1.0205\n",
            "Epoch 56/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9763 - loss: 0.1236 - val_acc: 0.7054 - val_loss: 1.0372\n",
            "Epoch 57/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9815 - loss: 0.1140 - val_acc: 0.7150 - val_loss: 0.9878\n",
            "Epoch 58/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9839 - loss: 0.1036 - val_acc: 0.7188 - val_loss: 1.0178\n",
            "Epoch 59/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9836 - loss: 0.0928 - val_acc: 0.7188 - val_loss: 1.0700\n",
            "Epoch 60/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.9860 - loss: 0.0909 - val_acc: 0.6930 - val_loss: 1.1042\n",
            "Epoch 61/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9814 - loss: 0.0995 - val_acc: 0.7212 - val_loss: 1.0187\n",
            "Epoch 62/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9890 - loss: 0.0836 - val_acc: 0.7145 - val_loss: 1.0689\n",
            "Epoch 63/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9874 - loss: 0.0832 - val_acc: 0.7140 - val_loss: 1.0433\n",
            "Epoch 64/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9906 - loss: 0.0734 - val_acc: 0.7126 - val_loss: 1.0591\n",
            "Epoch 65/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9890 - loss: 0.0706 - val_acc: 0.7212 - val_loss: 1.0338\n",
            "Epoch 66/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9925 - loss: 0.0675 - val_acc: 0.7216 - val_loss: 1.0494\n",
            "Epoch 67/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9943 - loss: 0.0552 - val_acc: 0.7231 - val_loss: 1.0564\n",
            "Epoch 68/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9942 - loss: 0.0483 - val_acc: 0.7293 - val_loss: 1.0405\n",
            "Epoch 69/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9965 - loss: 0.0466 - val_acc: 0.7016 - val_loss: 1.2197\n",
            "Epoch 70/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9910 - loss: 0.0634 - val_acc: 0.7178 - val_loss: 1.0822\n",
            "Epoch 71/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9951 - loss: 0.0479 - val_acc: 0.7302 - val_loss: 1.0503\n",
            "Epoch 72/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9977 - loss: 0.0390 - val_acc: 0.7221 - val_loss: 1.0930\n",
            "Epoch 73/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9962 - loss: 0.0443 - val_acc: 0.7164 - val_loss: 1.0914\n",
            "Epoch 74/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9924 - loss: 0.0568 - val_acc: 0.7097 - val_loss: 1.1882\n",
            "Epoch 75/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9924 - loss: 0.0623 - val_acc: 0.7045 - val_loss: 1.1733\n",
            "Epoch 76/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9920 - loss: 0.0471 - val_acc: 0.7235 - val_loss: 1.0867\n",
            "Epoch 77/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9995 - loss: 0.0275 - val_acc: 0.7169 - val_loss: 1.1072\n",
            "Epoch 78/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9997 - loss: 0.0246 - val_acc: 0.7121 - val_loss: 1.2087\n",
            "Epoch 79/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9982 - loss: 0.0323 - val_acc: 0.7269 - val_loss: 1.1130\n",
            "Epoch 80/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9983 - loss: 0.0248 - val_acc: 0.7255 - val_loss: 1.1211\n",
            "Epoch 81/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9977 - loss: 0.0274 - val_acc: 0.7183 - val_loss: 1.1754\n",
            "Epoch 82/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9986 - loss: 0.0258 - val_acc: 0.7235 - val_loss: 1.1383\n",
            "Epoch 83/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9998 - loss: 0.0173 - val_acc: 0.7374 - val_loss: 1.1465\n",
            "Epoch 84/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9994 - loss: 0.0167 - val_acc: 0.7274 - val_loss: 1.1461\n",
            "Epoch 85/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9995 - loss: 0.0160 - val_acc: 0.7202 - val_loss: 1.2021\n",
            "Epoch 86/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9985 - loss: 0.0231 - val_acc: 0.7193 - val_loss: 1.2206\n",
            "Epoch 87/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9991 - loss: 0.0210 - val_acc: 0.7212 - val_loss: 1.1771\n",
            "Epoch 88/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9967 - loss: 0.0268 - val_acc: 0.6954 - val_loss: 1.5153\n",
            "Epoch 89/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9799 - loss: 0.0697 - val_acc: 0.7083 - val_loss: 1.2758\n",
            "Epoch 90/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9530 - loss: 0.1356 - val_acc: 0.6897 - val_loss: 1.4145\n",
            "Epoch 91/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9620 - loss: 0.1119 - val_acc: 0.7159 - val_loss: 1.1522\n",
            "Epoch 92/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9990 - loss: 0.0213 - val_acc: 0.7216 - val_loss: 1.1836\n",
            "Epoch 93/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9976 - loss: 0.0169 - val_acc: 0.7355 - val_loss: 1.1712\n",
            "Epoch 94/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9981 - loss: 0.0199 - val_acc: 0.7316 - val_loss: 1.1779\n",
            "Epoch 95/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9992 - loss: 0.0115 - val_acc: 0.7378 - val_loss: 1.1886\n",
            "Epoch 96/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9995 - loss: 0.0099 - val_acc: 0.7378 - val_loss: 1.2217\n",
            "Epoch 97/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9991 - loss: 0.0124 - val_acc: 0.7264 - val_loss: 1.2513\n",
            "Epoch 98/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9989 - loss: 0.0139 - val_acc: 0.7340 - val_loss: 1.1981\n",
            "Epoch 99/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0070 - val_acc: 0.7350 - val_loss: 1.2085\n",
            "Epoch 100/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9998 - loss: 0.0088 - val_acc: 0.7336 - val_loss: 1.2066\n",
            "Epoch 101/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9996 - loss: 0.0076 - val_acc: 0.7321 - val_loss: 1.2162\n",
            "Epoch 102/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9991 - loss: 0.0130 - val_acc: 0.7321 - val_loss: 1.2213\n",
            "Epoch 103/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9996 - loss: 0.0084 - val_acc: 0.7312 - val_loss: 1.2552\n",
            "Epoch 104/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9996 - loss: 0.0077 - val_acc: 0.7302 - val_loss: 1.2566\n",
            "Epoch 105/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9995 - loss: 0.0085 - val_acc: 0.7259 - val_loss: 1.2371\n",
            "Epoch 106/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9990 - loss: 0.0097 - val_acc: 0.7197 - val_loss: 1.3522\n",
            "Epoch 107/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9962 - loss: 0.0221 - val_acc: 0.7207 - val_loss: 1.4116\n",
            "Epoch 108/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9724 - loss: 0.0915 - val_acc: 0.6554 - val_loss: 1.6031\n",
            "Epoch 109/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9228 - loss: 0.2149 - val_acc: 0.7269 - val_loss: 1.1433\n",
            "Epoch 110/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9995 - loss: 0.0169 - val_acc: 0.7193 - val_loss: 1.2002\n",
            "Epoch 111/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9985 - loss: 0.0118 - val_acc: 0.7359 - val_loss: 1.1966\n",
            "Epoch 112/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9982 - loss: 0.0115 - val_acc: 0.7302 - val_loss: 1.2188\n",
            "Epoch 113/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9999 - loss: 0.0063 - val_acc: 0.7183 - val_loss: 1.2844\n",
            "Epoch 114/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - acc: 0.9999 - loss: 0.0077 - val_acc: 0.7288 - val_loss: 1.2602\n",
            "Epoch 115/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9998 - loss: 0.0077 - val_acc: 0.7316 - val_loss: 1.2350\n",
            "Epoch 116/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - acc: 0.9993 - loss: 0.0079 - val_acc: 0.7293 - val_loss: 1.2595\n",
            "Epoch 117/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9992 - loss: 0.0082 - val_acc: 0.7374 - val_loss: 1.2406\n",
            "Epoch 118/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.9995 - loss: 0.0060 - val_acc: 0.7359 - val_loss: 1.2406\n",
            "Epoch 119/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9983 - loss: 0.0079 - val_acc: 0.7359 - val_loss: 1.2522\n",
            "Epoch 120/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9997 - loss: 0.0058 - val_acc: 0.7321 - val_loss: 1.2728\n",
            "Epoch 121/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9995 - loss: 0.0065 - val_acc: 0.7355 - val_loss: 1.2582\n",
            "Epoch 122/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9999 - loss: 0.0041 - val_acc: 0.7355 - val_loss: 1.2660\n",
            "Epoch 123/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9994 - loss: 0.0061 - val_acc: 0.7264 - val_loss: 1.3163\n",
            "Epoch 124/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9996 - loss: 0.0093 - val_acc: 0.7293 - val_loss: 1.2557\n",
            "Epoch 125/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.9974 - loss: 0.0118 - val_acc: 0.6945 - val_loss: 1.6306\n",
            "Epoch 126/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9713 - loss: 0.1001 - val_acc: 0.6420 - val_loss: 1.7816\n",
            "Epoch 127/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 0.9679 - loss: 0.1096 - val_acc: 0.7169 - val_loss: 1.2901\n",
            "Epoch 128/128\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - acc: 1.0000 - loss: 0.0112 - val_acc: 0.7383 - val_loss: 1.2217\n"
          ]
        }
      ],
      "source": [
        "\n",
        "hist_cnn04 = model_cnn04.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    validation_data=(X_val_cnn, y_val),\n",
        "    batch_size=64,\n",
        "    epochs=128,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vApFwDzRfYy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pApNI5zIXR0W"
      },
      "outputs": [],
      "source": [
        "model_cnn05 = Sequential()\n",
        "\n",
        "model_cnn05.add(Conv2D(32, 3, activation='relu', input_shape=input_shape, padding='same'))\n",
        "model_cnn05.add(Conv2D(32, 3, activation='relu', padding='same'))\n",
        "model_cnn05.add(MaxPooling2D(2, strides=(2,2), padding='same'))\n",
        "model_cnn05.add(Dropout(0.3))\n",
        "\n",
        "model_cnn05.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model_cnn05.add(Conv2D(64, 3, activation='relu', padding='same'))\n",
        "model_cnn05.add(MaxPooling2D(2, strides=(2,2), padding='same'))\n",
        "model_cnn05.add(Dropout(0.3))\n",
        "\n",
        "model_cnn05.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
        "model_cnn05.add(Conv2D(128, 3, activation='relu', padding='same'))\n",
        "model_cnn05.add(MaxPooling2D(2, strides=(2,2), padding='same'))\n",
        "model_cnn05.add(Dropout(0.4))\n",
        "\n",
        "model_cnn05.add(Flatten())\n",
        "model_cnn05.add(Dense(128, activation='relu'))\n",
        "model_cnn05.add(Dropout(0.5))\n",
        "\n",
        "model_cnn05.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_cnn05.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz1mNGF9aRBI",
        "outputId": "bf8ceaa5-e073-4180-f6ae-29308babc7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 114ms/step - acc: 0.1161 - loss: 3.9394 - val_acc: 0.2188 - val_loss: 2.2827\n",
            "Epoch 2/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - acc: 0.1392 - loss: 2.2871 - val_acc: 0.1973 - val_loss: 2.1846\n",
            "Epoch 3/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.1803 - loss: 2.1907 - val_acc: 0.2383 - val_loss: 2.0327\n",
            "Epoch 4/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.2111 - loss: 2.1130 - val_acc: 0.2936 - val_loss: 1.9608\n",
            "Epoch 5/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.2638 - loss: 2.0157 - val_acc: 0.2989 - val_loss: 1.8764\n",
            "Epoch 6/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.2838 - loss: 1.9211 - val_acc: 0.3241 - val_loss: 1.7903\n",
            "Epoch 7/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.3077 - loss: 1.8689 - val_acc: 0.3570 - val_loss: 1.7499\n",
            "Epoch 8/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.3216 - loss: 1.8346 - val_acc: 0.3808 - val_loss: 1.6741\n",
            "Epoch 9/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.3373 - loss: 1.7635 - val_acc: 0.4066 - val_loss: 1.5862\n",
            "Epoch 10/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.3721 - loss: 1.6689 - val_acc: 0.4380 - val_loss: 1.5524\n",
            "Epoch 11/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.3673 - loss: 1.6699 - val_acc: 0.4652 - val_loss: 1.5027\n",
            "Epoch 12/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.4058 - loss: 1.6019 - val_acc: 0.4709 - val_loss: 1.4610\n",
            "Epoch 13/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.4150 - loss: 1.5656 - val_acc: 0.5024 - val_loss: 1.3778\n",
            "Epoch 14/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.4444 - loss: 1.4976 - val_acc: 0.4833 - val_loss: 1.4023\n",
            "Epoch 15/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.4620 - loss: 1.4654 - val_acc: 0.5100 - val_loss: 1.3328\n",
            "Epoch 16/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.4730 - loss: 1.4372 - val_acc: 0.5267 - val_loss: 1.2869\n",
            "Epoch 17/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5118 - loss: 1.3589 - val_acc: 0.5596 - val_loss: 1.2285\n",
            "Epoch 18/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.4999 - loss: 1.3596 - val_acc: 0.5367 - val_loss: 1.2411\n",
            "Epoch 19/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5187 - loss: 1.3476 - val_acc: 0.5782 - val_loss: 1.1655\n",
            "Epoch 20/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5137 - loss: 1.3210 - val_acc: 0.5744 - val_loss: 1.1922\n",
            "Epoch 21/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5230 - loss: 1.2935 - val_acc: 0.5696 - val_loss: 1.1640\n",
            "Epoch 22/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5361 - loss: 1.2561 - val_acc: 0.5953 - val_loss: 1.1239\n",
            "Epoch 23/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5338 - loss: 1.2623 - val_acc: 0.5796 - val_loss: 1.1710\n",
            "Epoch 24/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5616 - loss: 1.2017 - val_acc: 0.5934 - val_loss: 1.0986\n",
            "Epoch 25/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5643 - loss: 1.1981 - val_acc: 0.6182 - val_loss: 1.0708\n",
            "Epoch 26/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.5782 - loss: 1.1705 - val_acc: 0.6168 - val_loss: 1.0514\n",
            "Epoch 27/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.5770 - loss: 1.1362 - val_acc: 0.6235 - val_loss: 1.0332\n",
            "Epoch 28/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.5785 - loss: 1.1404 - val_acc: 0.6149 - val_loss: 1.0851\n",
            "Epoch 29/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.5874 - loss: 1.1284 - val_acc: 0.6311 - val_loss: 1.0341\n",
            "Epoch 30/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6212 - loss: 1.0940 - val_acc: 0.6392 - val_loss: 1.0325\n",
            "Epoch 31/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6196 - loss: 1.0429 - val_acc: 0.6473 - val_loss: 1.0080\n",
            "Epoch 32/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6218 - loss: 1.0469 - val_acc: 0.6506 - val_loss: 0.9928\n",
            "Epoch 33/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6328 - loss: 1.0162 - val_acc: 0.6659 - val_loss: 0.9456\n",
            "Epoch 34/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6419 - loss: 0.9984 - val_acc: 0.6554 - val_loss: 0.9812\n",
            "Epoch 35/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6368 - loss: 1.0013 - val_acc: 0.6625 - val_loss: 0.9434\n",
            "Epoch 36/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6601 - loss: 0.9578 - val_acc: 0.6678 - val_loss: 0.9568\n",
            "Epoch 37/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6601 - loss: 0.9389 - val_acc: 0.6745 - val_loss: 0.9347\n",
            "Epoch 38/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.6549 - loss: 0.9565 - val_acc: 0.6697 - val_loss: 0.9402\n",
            "Epoch 39/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.6603 - loss: 0.9389 - val_acc: 0.6845 - val_loss: 0.9238\n",
            "Epoch 40/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6792 - loss: 0.9101 - val_acc: 0.6902 - val_loss: 0.8816\n",
            "Epoch 41/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.6715 - loss: 0.8978 - val_acc: 0.6840 - val_loss: 0.9033\n",
            "Epoch 42/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.6825 - loss: 0.8747 - val_acc: 0.6969 - val_loss: 0.8805\n",
            "Epoch 43/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.7025 - loss: 0.8335 - val_acc: 0.7045 - val_loss: 0.8607\n",
            "Epoch 44/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7010 - loss: 0.8414 - val_acc: 0.7078 - val_loss: 0.8483\n",
            "Epoch 45/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7144 - loss: 0.8321 - val_acc: 0.6978 - val_loss: 0.9035\n",
            "Epoch 46/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - acc: 0.7026 - loss: 0.8209 - val_acc: 0.7197 - val_loss: 0.8267\n",
            "Epoch 47/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7101 - loss: 0.8017 - val_acc: 0.7102 - val_loss: 0.8353\n",
            "Epoch 48/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.7200 - loss: 0.7871 - val_acc: 0.7040 - val_loss: 0.8480\n",
            "Epoch 49/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.7284 - loss: 0.7660 - val_acc: 0.7193 - val_loss: 0.8282\n",
            "Epoch 50/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7359 - loss: 0.7401 - val_acc: 0.7369 - val_loss: 0.7816\n",
            "Epoch 51/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7390 - loss: 0.7330 - val_acc: 0.7255 - val_loss: 0.8246\n",
            "Epoch 52/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7430 - loss: 0.7279 - val_acc: 0.7421 - val_loss: 0.7688\n",
            "Epoch 53/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7523 - loss: 0.7047 - val_acc: 0.7264 - val_loss: 0.8292\n",
            "Epoch 54/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7344 - loss: 0.7366 - val_acc: 0.7412 - val_loss: 0.7538\n",
            "Epoch 55/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.7354 - loss: 0.7109 - val_acc: 0.7140 - val_loss: 0.8522\n",
            "Epoch 56/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7520 - loss: 0.6992 - val_acc: 0.7412 - val_loss: 0.7814\n",
            "Epoch 57/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.7697 - loss: 0.6489 - val_acc: 0.7493 - val_loss: 0.7401\n",
            "Epoch 58/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.7694 - loss: 0.6621 - val_acc: 0.7374 - val_loss: 0.7929\n",
            "Epoch 59/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - acc: 0.7619 - loss: 0.6499 - val_acc: 0.7660 - val_loss: 0.7288\n",
            "Epoch 60/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7743 - loss: 0.6164 - val_acc: 0.7602 - val_loss: 0.7292\n",
            "Epoch 61/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7742 - loss: 0.6285 - val_acc: 0.7541 - val_loss: 0.7586\n",
            "Epoch 62/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7853 - loss: 0.6129 - val_acc: 0.7526 - val_loss: 0.7371\n",
            "Epoch 63/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7894 - loss: 0.5924 - val_acc: 0.7407 - val_loss: 0.7837\n",
            "Epoch 64/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8003 - loss: 0.5710 - val_acc: 0.7622 - val_loss: 0.7383\n",
            "Epoch 65/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7835 - loss: 0.6130 - val_acc: 0.7569 - val_loss: 0.7472\n",
            "Epoch 66/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.7943 - loss: 0.5820 - val_acc: 0.7645 - val_loss: 0.7172\n",
            "Epoch 67/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.8046 - loss: 0.5468 - val_acc: 0.7622 - val_loss: 0.7065\n",
            "Epoch 68/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.8017 - loss: 0.5355 - val_acc: 0.7750 - val_loss: 0.6875\n",
            "Epoch 69/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8141 - loss: 0.5293 - val_acc: 0.7731 - val_loss: 0.6970\n",
            "Epoch 70/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8112 - loss: 0.5145 - val_acc: 0.7788 - val_loss: 0.6764\n",
            "Epoch 71/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8237 - loss: 0.4929 - val_acc: 0.7788 - val_loss: 0.6836\n",
            "Epoch 72/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8247 - loss: 0.5026 - val_acc: 0.7807 - val_loss: 0.6923\n",
            "Epoch 73/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.8292 - loss: 0.4735 - val_acc: 0.7712 - val_loss: 0.7250\n",
            "Epoch 74/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8224 - loss: 0.5103 - val_acc: 0.7831 - val_loss: 0.7003\n",
            "Epoch 75/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8324 - loss: 0.4671 - val_acc: 0.7765 - val_loss: 0.6837\n",
            "Epoch 76/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.8320 - loss: 0.4659 - val_acc: 0.7803 - val_loss: 0.7086\n",
            "Epoch 77/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.8404 - loss: 0.4418 - val_acc: 0.7903 - val_loss: 0.6651\n",
            "Epoch 78/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.8372 - loss: 0.4596 - val_acc: 0.7869 - val_loss: 0.6730\n",
            "Epoch 79/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8523 - loss: 0.4216 - val_acc: 0.7784 - val_loss: 0.7271\n",
            "Epoch 80/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8333 - loss: 0.4709 - val_acc: 0.7850 - val_loss: 0.6811\n",
            "Epoch 81/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8501 - loss: 0.4134 - val_acc: 0.7855 - val_loss: 0.6588\n",
            "Epoch 82/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8497 - loss: 0.4160 - val_acc: 0.7941 - val_loss: 0.6680\n",
            "Epoch 83/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8673 - loss: 0.3710 - val_acc: 0.7917 - val_loss: 0.6818\n",
            "Epoch 84/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8603 - loss: 0.3940 - val_acc: 0.7950 - val_loss: 0.6689\n",
            "Epoch 85/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.8656 - loss: 0.3597 - val_acc: 0.7912 - val_loss: 0.6790\n",
            "Epoch 86/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.8655 - loss: 0.3788 - val_acc: 0.7803 - val_loss: 0.7157\n",
            "Epoch 87/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.8643 - loss: 0.3721 - val_acc: 0.7831 - val_loss: 0.6941\n",
            "Epoch 88/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8754 - loss: 0.3612 - val_acc: 0.7965 - val_loss: 0.6846\n",
            "Epoch 89/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8732 - loss: 0.3518 - val_acc: 0.7898 - val_loss: 0.6991\n",
            "Epoch 90/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8807 - loss: 0.3497 - val_acc: 0.8065 - val_loss: 0.6745\n",
            "Epoch 91/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8730 - loss: 0.3426 - val_acc: 0.7936 - val_loss: 0.6880\n",
            "Epoch 92/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8741 - loss: 0.3513 - val_acc: 0.8012 - val_loss: 0.6532\n",
            "Epoch 93/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8768 - loss: 0.3350 - val_acc: 0.8027 - val_loss: 0.6803\n",
            "Epoch 94/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.8905 - loss: 0.3074 - val_acc: 0.8017 - val_loss: 0.6785\n",
            "Epoch 95/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8930 - loss: 0.3060 - val_acc: 0.7855 - val_loss: 0.7247\n",
            "Epoch 96/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.8887 - loss: 0.3030 - val_acc: 0.8108 - val_loss: 0.6921\n",
            "Epoch 97/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.8963 - loss: 0.3000 - val_acc: 0.8008 - val_loss: 0.6728\n",
            "Epoch 98/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.8975 - loss: 0.2981 - val_acc: 0.8036 - val_loss: 0.6720\n",
            "Epoch 99/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8989 - loss: 0.2809 - val_acc: 0.8031 - val_loss: 0.7140\n",
            "Epoch 100/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8919 - loss: 0.2880 - val_acc: 0.8136 - val_loss: 0.6885\n",
            "Epoch 101/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8990 - loss: 0.2867 - val_acc: 0.8084 - val_loss: 0.7000\n",
            "Epoch 102/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9033 - loss: 0.2752 - val_acc: 0.8079 - val_loss: 0.6977\n",
            "Epoch 103/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9034 - loss: 0.2828 - val_acc: 0.8160 - val_loss: 0.6639\n",
            "Epoch 104/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9030 - loss: 0.2688 - val_acc: 0.8179 - val_loss: 0.6609\n",
            "Epoch 105/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.8876 - loss: 0.2930 - val_acc: 0.8070 - val_loss: 0.6750\n",
            "Epoch 106/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9044 - loss: 0.2577 - val_acc: 0.8027 - val_loss: 0.6853\n",
            "Epoch 107/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.9170 - loss: 0.2363 - val_acc: 0.8055 - val_loss: 0.7017\n",
            "Epoch 108/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9172 - loss: 0.2439 - val_acc: 0.8184 - val_loss: 0.6868\n",
            "Epoch 109/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9137 - loss: 0.2489 - val_acc: 0.8093 - val_loss: 0.6797\n",
            "Epoch 110/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9175 - loss: 0.2355 - val_acc: 0.8127 - val_loss: 0.6652\n",
            "Epoch 111/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9261 - loss: 0.2183 - val_acc: 0.8141 - val_loss: 0.7237\n",
            "Epoch 112/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9140 - loss: 0.2383 - val_acc: 0.8079 - val_loss: 0.7374\n",
            "Epoch 113/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9218 - loss: 0.2258 - val_acc: 0.8127 - val_loss: 0.7102\n",
            "Epoch 114/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9155 - loss: 0.2378 - val_acc: 0.8012 - val_loss: 0.7802\n",
            "Epoch 115/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9209 - loss: 0.2183 - val_acc: 0.8189 - val_loss: 0.7248\n",
            "Epoch 116/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.9137 - loss: 0.2323 - val_acc: 0.8117 - val_loss: 0.7217\n",
            "Epoch 117/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9140 - loss: 0.2420 - val_acc: 0.8179 - val_loss: 0.7118\n",
            "Epoch 118/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9236 - loss: 0.2102 - val_acc: 0.8222 - val_loss: 0.6999\n",
            "Epoch 119/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9288 - loss: 0.1990 - val_acc: 0.8127 - val_loss: 0.7285\n",
            "Epoch 120/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9217 - loss: 0.2195 - val_acc: 0.8255 - val_loss: 0.7129\n",
            "Epoch 121/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9318 - loss: 0.1908 - val_acc: 0.8203 - val_loss: 0.7292\n",
            "Epoch 122/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9334 - loss: 0.2029 - val_acc: 0.8184 - val_loss: 0.7440\n",
            "Epoch 123/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9323 - loss: 0.2052 - val_acc: 0.8227 - val_loss: 0.6750\n",
            "Epoch 124/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9354 - loss: 0.1769 - val_acc: 0.8217 - val_loss: 0.7182\n",
            "Epoch 125/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - acc: 0.9378 - loss: 0.1933 - val_acc: 0.8155 - val_loss: 0.7453\n",
            "Epoch 126/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.9407 - loss: 0.1733 - val_acc: 0.8184 - val_loss: 0.7065\n",
            "Epoch 127/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9323 - loss: 0.1976 - val_acc: 0.8251 - val_loss: 0.6940\n",
            "Epoch 128/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9402 - loss: 0.1640 - val_acc: 0.8260 - val_loss: 0.6874\n",
            "Epoch 129/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9356 - loss: 0.1855 - val_acc: 0.8270 - val_loss: 0.7094\n",
            "Epoch 130/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9386 - loss: 0.1794 - val_acc: 0.8108 - val_loss: 0.7862\n",
            "Epoch 131/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9379 - loss: 0.1719 - val_acc: 0.8251 - val_loss: 0.6981\n",
            "Epoch 132/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9440 - loss: 0.1651 - val_acc: 0.8222 - val_loss: 0.7368\n",
            "Epoch 133/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.9473 - loss: 0.1551 - val_acc: 0.8189 - val_loss: 0.7459\n",
            "Epoch 134/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9398 - loss: 0.1645 - val_acc: 0.8227 - val_loss: 0.7106\n",
            "Epoch 135/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9441 - loss: 0.1613 - val_acc: 0.8275 - val_loss: 0.7249\n",
            "Epoch 136/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9380 - loss: 0.1652 - val_acc: 0.8279 - val_loss: 0.7350\n",
            "Epoch 137/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9502 - loss: 0.1370 - val_acc: 0.8260 - val_loss: 0.7726\n",
            "Epoch 138/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9423 - loss: 0.1532 - val_acc: 0.8260 - val_loss: 0.7492\n",
            "Epoch 139/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9390 - loss: 0.1675 - val_acc: 0.8313 - val_loss: 0.7146\n",
            "Epoch 140/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9553 - loss: 0.1286 - val_acc: 0.8265 - val_loss: 0.7280\n",
            "Epoch 141/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9504 - loss: 0.1305 - val_acc: 0.8270 - val_loss: 0.8014\n",
            "Epoch 142/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9468 - loss: 0.1384 - val_acc: 0.8294 - val_loss: 0.7932\n",
            "Epoch 143/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9552 - loss: 0.1321 - val_acc: 0.8232 - val_loss: 0.7954\n",
            "Epoch 144/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9514 - loss: 0.1282 - val_acc: 0.8174 - val_loss: 0.7817\n",
            "Epoch 145/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9441 - loss: 0.1586 - val_acc: 0.8275 - val_loss: 0.7160\n",
            "Epoch 146/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9538 - loss: 0.1402 - val_acc: 0.8308 - val_loss: 0.7873\n",
            "Epoch 147/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9525 - loss: 0.1329 - val_acc: 0.8227 - val_loss: 0.8147\n",
            "Epoch 148/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9483 - loss: 0.1630 - val_acc: 0.8232 - val_loss: 0.7864\n",
            "Epoch 149/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9529 - loss: 0.1401 - val_acc: 0.8370 - val_loss: 0.7488\n",
            "Epoch 150/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9523 - loss: 0.1402 - val_acc: 0.8251 - val_loss: 0.8486\n",
            "Epoch 151/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9566 - loss: 0.1218 - val_acc: 0.8213 - val_loss: 0.8172\n",
            "Epoch 152/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9590 - loss: 0.1207 - val_acc: 0.8232 - val_loss: 0.8136\n",
            "Epoch 153/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9546 - loss: 0.1391 - val_acc: 0.8332 - val_loss: 0.7448\n",
            "Epoch 154/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9507 - loss: 0.1496 - val_acc: 0.8255 - val_loss: 0.7453\n",
            "Epoch 155/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9602 - loss: 0.1205 - val_acc: 0.8365 - val_loss: 0.7237\n",
            "Epoch 156/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9528 - loss: 0.1368 - val_acc: 0.8198 - val_loss: 0.8161\n",
            "Epoch 157/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9623 - loss: 0.1132 - val_acc: 0.8236 - val_loss: 0.8037\n",
            "Epoch 158/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9624 - loss: 0.1174 - val_acc: 0.8317 - val_loss: 0.8176\n",
            "Epoch 159/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9611 - loss: 0.1132 - val_acc: 0.8356 - val_loss: 0.7797\n",
            "Epoch 160/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9607 - loss: 0.1143 - val_acc: 0.8260 - val_loss: 0.7704\n",
            "Epoch 161/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9623 - loss: 0.1044 - val_acc: 0.8294 - val_loss: 0.8259\n",
            "Epoch 162/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9587 - loss: 0.1131 - val_acc: 0.8141 - val_loss: 0.9271\n",
            "Epoch 163/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9593 - loss: 0.1253 - val_acc: 0.8308 - val_loss: 0.7752\n",
            "Epoch 164/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.9615 - loss: 0.1101 - val_acc: 0.8289 - val_loss: 0.8471\n",
            "Epoch 165/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9689 - loss: 0.0925 - val_acc: 0.8313 - val_loss: 0.8332\n",
            "Epoch 166/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9593 - loss: 0.1241 - val_acc: 0.8270 - val_loss: 0.8095\n",
            "Epoch 167/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9618 - loss: 0.1055 - val_acc: 0.8246 - val_loss: 0.8411\n",
            "Epoch 168/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9641 - loss: 0.0992 - val_acc: 0.8313 - val_loss: 0.8448\n",
            "Epoch 169/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9685 - loss: 0.1007 - val_acc: 0.8332 - val_loss: 0.8263\n",
            "Epoch 170/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9647 - loss: 0.1040 - val_acc: 0.8284 - val_loss: 0.8546\n",
            "Epoch 171/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9579 - loss: 0.1214 - val_acc: 0.8327 - val_loss: 0.7547\n",
            "Epoch 172/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9695 - loss: 0.0967 - val_acc: 0.8351 - val_loss: 0.8020\n",
            "Epoch 173/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9682 - loss: 0.0981 - val_acc: 0.8389 - val_loss: 0.8003\n",
            "Epoch 174/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.9693 - loss: 0.0841 - val_acc: 0.8303 - val_loss: 0.8244\n",
            "Epoch 175/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9678 - loss: 0.0939 - val_acc: 0.8284 - val_loss: 0.8747\n",
            "Epoch 176/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9608 - loss: 0.1033 - val_acc: 0.8303 - val_loss: 0.8960\n",
            "Epoch 177/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - acc: 0.9685 - loss: 0.1066 - val_acc: 0.8332 - val_loss: 0.7881\n",
            "Epoch 178/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9649 - loss: 0.1014 - val_acc: 0.8317 - val_loss: 0.8231\n",
            "Epoch 179/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9706 - loss: 0.0892 - val_acc: 0.8327 - val_loss: 0.8547\n",
            "Epoch 180/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9670 - loss: 0.0918 - val_acc: 0.8289 - val_loss: 0.8615\n",
            "Epoch 181/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9664 - loss: 0.0947 - val_acc: 0.8322 - val_loss: 0.8818\n",
            "Epoch 182/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9603 - loss: 0.1156 - val_acc: 0.8222 - val_loss: 0.9273\n",
            "Epoch 183/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9644 - loss: 0.0979 - val_acc: 0.8332 - val_loss: 0.8416\n",
            "Epoch 184/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.9718 - loss: 0.0804 - val_acc: 0.8317 - val_loss: 0.8992\n",
            "Epoch 185/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.9592 - loss: 0.1193 - val_acc: 0.8303 - val_loss: 0.8299\n",
            "Epoch 186/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9702 - loss: 0.0873 - val_acc: 0.8194 - val_loss: 0.8613\n",
            "Epoch 187/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9643 - loss: 0.1031 - val_acc: 0.8308 - val_loss: 0.8522\n",
            "Epoch 188/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9662 - loss: 0.0985 - val_acc: 0.8317 - val_loss: 0.8440\n",
            "Epoch 189/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9721 - loss: 0.0776 - val_acc: 0.8360 - val_loss: 0.8456\n",
            "Epoch 190/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9707 - loss: 0.0892 - val_acc: 0.8279 - val_loss: 0.9068\n",
            "Epoch 191/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9740 - loss: 0.0786 - val_acc: 0.8389 - val_loss: 0.8041\n",
            "Epoch 192/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9686 - loss: 0.0864 - val_acc: 0.8379 - val_loss: 0.8807\n",
            "Epoch 193/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9705 - loss: 0.0904 - val_acc: 0.8351 - val_loss: 0.8836\n",
            "Epoch 194/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.9735 - loss: 0.0767 - val_acc: 0.8413 - val_loss: 0.8549\n",
            "Epoch 195/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.9656 - loss: 0.1004 - val_acc: 0.8322 - val_loss: 0.8881\n",
            "Epoch 196/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.9704 - loss: 0.0832 - val_acc: 0.8365 - val_loss: 0.8330\n",
            "Epoch 197/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9764 - loss: 0.0730 - val_acc: 0.8313 - val_loss: 0.8883\n",
            "Epoch 198/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9707 - loss: 0.0853 - val_acc: 0.8332 - val_loss: 0.8584\n",
            "Epoch 199/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9758 - loss: 0.0738 - val_acc: 0.8317 - val_loss: 0.8432\n",
            "Epoch 200/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9757 - loss: 0.0680 - val_acc: 0.8375 - val_loss: 0.8329\n",
            "Epoch 201/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9730 - loss: 0.0769 - val_acc: 0.8251 - val_loss: 0.9538\n",
            "Epoch 202/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9703 - loss: 0.0813 - val_acc: 0.8389 - val_loss: 0.8732\n",
            "Epoch 203/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9746 - loss: 0.0734 - val_acc: 0.8294 - val_loss: 0.8928\n",
            "Epoch 204/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9701 - loss: 0.0793 - val_acc: 0.8337 - val_loss: 0.9238\n",
            "Epoch 205/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9733 - loss: 0.0812 - val_acc: 0.8403 - val_loss: 0.8052\n",
            "Epoch 206/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9738 - loss: 0.0712 - val_acc: 0.8337 - val_loss: 0.8527\n",
            "Epoch 207/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9737 - loss: 0.0800 - val_acc: 0.8356 - val_loss: 0.8820\n",
            "Epoch 208/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9703 - loss: 0.0928 - val_acc: 0.8398 - val_loss: 0.8793\n",
            "Epoch 209/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9813 - loss: 0.0650 - val_acc: 0.8470 - val_loss: 0.8410\n",
            "Epoch 210/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9718 - loss: 0.0790 - val_acc: 0.8289 - val_loss: 0.9394\n",
            "Epoch 211/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9727 - loss: 0.0684 - val_acc: 0.8270 - val_loss: 0.8898\n",
            "Epoch 212/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9768 - loss: 0.0652 - val_acc: 0.8446 - val_loss: 0.8926\n",
            "Epoch 213/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9772 - loss: 0.0664 - val_acc: 0.8389 - val_loss: 0.8395\n",
            "Epoch 214/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9812 - loss: 0.0573 - val_acc: 0.8432 - val_loss: 0.8973\n",
            "Epoch 215/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9769 - loss: 0.0631 - val_acc: 0.8332 - val_loss: 0.9085\n",
            "Epoch 216/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9758 - loss: 0.0703 - val_acc: 0.8337 - val_loss: 0.9330\n",
            "Epoch 217/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9777 - loss: 0.0610 - val_acc: 0.8379 - val_loss: 0.9420\n",
            "Epoch 218/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9767 - loss: 0.0652 - val_acc: 0.8384 - val_loss: 0.8746\n",
            "Epoch 219/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9760 - loss: 0.0697 - val_acc: 0.8317 - val_loss: 0.9064\n",
            "Epoch 220/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9690 - loss: 0.0854 - val_acc: 0.8284 - val_loss: 0.9356\n",
            "Epoch 221/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9792 - loss: 0.0612 - val_acc: 0.8422 - val_loss: 0.8684\n",
            "Epoch 222/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9793 - loss: 0.0656 - val_acc: 0.8465 - val_loss: 0.9158\n",
            "Epoch 223/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9745 - loss: 0.0689 - val_acc: 0.8370 - val_loss: 0.8753\n",
            "Epoch 224/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9803 - loss: 0.0626 - val_acc: 0.8398 - val_loss: 0.8888\n",
            "Epoch 225/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9757 - loss: 0.0658 - val_acc: 0.8279 - val_loss: 0.9945\n",
            "Epoch 226/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9764 - loss: 0.0675 - val_acc: 0.8365 - val_loss: 0.9169\n",
            "Epoch 227/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9810 - loss: 0.0515 - val_acc: 0.8360 - val_loss: 0.9132\n",
            "Epoch 228/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9801 - loss: 0.0532 - val_acc: 0.8313 - val_loss: 0.8897\n",
            "Epoch 229/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9817 - loss: 0.0562 - val_acc: 0.8332 - val_loss: 0.9767\n",
            "Epoch 230/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9815 - loss: 0.0567 - val_acc: 0.8279 - val_loss: 0.9524\n",
            "Epoch 231/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9808 - loss: 0.0518 - val_acc: 0.8398 - val_loss: 0.9079\n",
            "Epoch 232/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9721 - loss: 0.0791 - val_acc: 0.8332 - val_loss: 0.9274\n",
            "Epoch 233/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9754 - loss: 0.0800 - val_acc: 0.8327 - val_loss: 0.8630\n",
            "Epoch 234/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9756 - loss: 0.0719 - val_acc: 0.8403 - val_loss: 0.8992\n",
            "Epoch 235/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9837 - loss: 0.0482 - val_acc: 0.8398 - val_loss: 0.9179\n",
            "Epoch 236/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9825 - loss: 0.0530 - val_acc: 0.8418 - val_loss: 0.9080\n",
            "Epoch 237/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9811 - loss: 0.0596 - val_acc: 0.8451 - val_loss: 0.8573\n",
            "Epoch 238/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - acc: 0.9716 - loss: 0.0742 - val_acc: 0.8308 - val_loss: 0.9211\n",
            "Epoch 239/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.9772 - loss: 0.0684 - val_acc: 0.8370 - val_loss: 0.9620\n",
            "Epoch 240/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - acc: 0.9791 - loss: 0.0722 - val_acc: 0.8432 - val_loss: 0.9037\n",
            "Epoch 241/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.9810 - loss: 0.0558 - val_acc: 0.8489 - val_loss: 0.8762\n",
            "Epoch 242/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9820 - loss: 0.0560 - val_acc: 0.8370 - val_loss: 0.9549\n",
            "Epoch 243/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9778 - loss: 0.0668 - val_acc: 0.8408 - val_loss: 0.8905\n",
            "Epoch 244/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9818 - loss: 0.0544 - val_acc: 0.8317 - val_loss: 0.9625\n",
            "Epoch 245/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - acc: 0.9780 - loss: 0.0674 - val_acc: 0.8394 - val_loss: 0.9541\n",
            "Epoch 246/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - acc: 0.9814 - loss: 0.0565 - val_acc: 0.8384 - val_loss: 0.9390\n",
            "Epoch 247/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - acc: 0.9853 - loss: 0.0449 - val_acc: 0.8341 - val_loss: 0.9932\n",
            "Epoch 248/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9833 - loss: 0.0465 - val_acc: 0.8370 - val_loss: 1.0361\n",
            "Epoch 249/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9824 - loss: 0.0592 - val_acc: 0.8365 - val_loss: 1.0242\n",
            "Epoch 250/250\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - acc: 0.9840 - loss: 0.0459 - val_acc: 0.8398 - val_loss: 0.9600\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "hist_cnn05 = model_cnn05.fit(\n",
        "    X_train_cnn, y_train,\n",
        "    validation_data=(X_val_cnn, y_val),\n",
        "    batch_size=64,\n",
        "    epochs=250,\n",
        "    verbose=1\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAdIT6MkTJm_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CLQp5ieLnuL9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}